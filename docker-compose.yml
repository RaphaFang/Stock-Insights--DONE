services:
  spark-driver-sec:
    image: bitnami/spark:latest
    volumes:
      - ./sp:/opt/spark-apps
      - ./.ivy2:/opt/bitnami/spark/.ivy2
      - ./checkpoints:/app/tmp/spark_checkpoints
      - ./java_udf:/opt/java_udf
      # test, 這邊加上java_udf檔案，
    working_dir: /opt/spark-apps
    ports:
      - "4040-4045:4040-4045"
    network_mode: host
    command: >
      bash -c "
      javac -cp /opt/bitnami/spark/jars/* /opt/java_udf/VWAPStatefulUDF.java &&
      jar -cvf /opt/spark-apps/vwap_udf.jar -C /opt/java_udf/ VWAPStatefulUDF.class &&
      pip install --user pyspark==3.5.2 kafka-python==2.0.2 six &&
      mkdir -p /opt/bitnami/spark/.ivy2/local &&
      spark-submit
      --master local[2]
      --conf spark.sql.session.timeZone=Asia/Taipei
      --conf spark.jars.ivy=/opt/bitnami/spark/.ivy2
      --conf spark.ui.enabled=false
      --conf spark.driver.bindAddress=10.0.1.231
      --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.2,org.apache.kafka:kafka-clients:3.8.0
      /opt/spark-apps/spark_application_first.py
      "
    dns:
      - 8.8.8.8
    environment:
      KAFKA_BROKER: 10.0.1.138:9092
      SPARK_LOCAL_IP: 10.0.1.231
      SPARK_PUBLIC_DNS: 10.0.1.231
      SPARK_DRIVER_BIND_ADDRESS: 10.0.1.231
      SPARK_DRIVER_HOST: 10.0.1.231
      SPARK_DRIVER_PORT: 4040
      SPARK_BLOCKMANAGER_PORT: 4041

  spark-driver-ma:
    image: bitnami/spark:latest
    volumes:
      - ./sp:/opt/spark-apps
      - ./.ivy2:/opt/bitnami/spark/.ivy2
      - ./checkpoints:/app/tmp/spark_checkpoints
    working_dir: /opt/spark-apps
    ports:
      - "4046-4050:4046-4050"
    network_mode: host
    command: >
      bash -c "
      pip install --user pyspark==3.5.2 kafka-python==2.0.2 six &&
      mkdir -p /opt/bitnami/spark/.ivy2/local &&
      spark-submit
      --master local[2]
      --conf spark.sql.session.timeZone=Asia/Taipei
      --conf spark.jars.ivy=/opt/bitnami/spark/.ivy2
      --conf spark.ui.enabled=false
      --conf spark.driver.bindAddress=10.0.1.231
      --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.2,org.apache.kafka:kafka-clients:3.8.0
      /opt/spark-apps/spark_ma.py
      "
    dns:
      - 8.8.8.8
    environment:
      KAFKA_BROKER: 10.0.1.138:9092
      SPARK_LOCAL_IP: 10.0.1.231
      SPARK_PUBLIC_DNS: 10.0.1.231
      SPARK_DRIVER_BIND_ADDRESS: 10.0.1.231
      SPARK_DRIVER_HOST: 10.0.1.231
      SPARK_DRIVER_PORT: 4046
      SPARK_BLOCKMANAGER_PORT: 4047
# 本地------------------------------------------
# networks:
#   kafka-net:
#     name: kafka_stack_kafka-net
#     external: true
# 可以運作的swarm版本 -----------------------------------------------------------------------------
# services:
#   spark-driver-sec:
#     image: bitnami/spark:latest
#     deploy:
#       placement:
#         constraints:
#           - "node.hostname == ip-10-0-1-231"
#     volumes:
#       - ./sp:/opt/spark-apps
#       - ./.ivy2:/opt/bitnami/spark/.ivy2
#       - ./checkpoints:/app/tmp/spark_checkpoints
#     working_dir: /opt/spark-apps
#     ports:
#       - "4040-4045:4040-4045"
#     command: >
#       bash -c "
#       pip install --user kafka-python==2.0.2 six &&
#       mkdir -p /opt/bitnami/spark/.ivy2/local &&
#       spark-submit
#       --master local[2]
#       --conf spark.sql.session.timeZone=Asia/Taipei
#       --conf spark.jars.ivy=/opt/bitnami/spark/.ivy2
#       --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.2,org.apache.kafka:kafka-clients:3.8.0
#       /opt/spark-apps/spark_application_first.py
#       "
#     dns:
#       - 8.8.8.8
#     environment:
#       KAFKA_BROKER: kafka:9092
#     networks:
#       - kafka-net

#   spark-driver-ma:
#     image: bitnami/spark:latest
#     deploy:
#       placement:
#         constraints:
#           - "node.hostname == ip-10-0-1-231"
#     volumes:
#       - ./sp:/opt/spark-apps
#       - ./.ivy2:/opt/bitnami/spark/.ivy2
#       - ./checkpoints:/app/tmp/spark_checkpoints
#     working_dir: /opt/spark-apps
#     ports:
#       - "4046-4050:4046-4050"
#     command: >
#       bash -c "
#       pip install --user kafka-python==2.0.2 six &&
#       mkdir -p /opt/bitnami/spark/.ivy2/local &&
#       spark-submit
#       --master local[2]
#       --conf spark.sql.session.timeZone=Asia/Taipei
#       --conf spark.jars.ivy=/opt/bitnami/spark/.ivy2
#       --conf spark.driver.bindAddress=10.0.1.231
#       --conf spark.driver.host=10.0.1.231
#       --conf spark.driver.port=4046
#       --conf spark.blockManager.port=4047
#       --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.2,org.apache.kafka:kafka-clients:3.8.0
#       /opt/spark-apps/spark_ma.py
#       "
#     dns:
#       - 8.8.8.8
#     environment:
#       KAFKA_BROKER: kafka:9092
#     networks:
#       - kafka-net

# networks:
#   kafka-net:
#     name: kafka_stack_kafka-net
#     external: true
